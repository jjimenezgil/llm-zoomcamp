{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184ee1b9-fd92-4063-9e0b-ee0b0e21bae0",
   "metadata": {},
   "source": [
    "# Homework: Vector Search\n",
    "\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4726353b-1bc8-4910-9b5b-657c9dbd8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import requests \n",
    "import numpy as np\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a38f0d-955a-4c8e-85d0-69853f6c38b1",
   "metadata": {},
   "source": [
    "## Q1. Getting the embeddings model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b26ebfa-30c5-4821-bd86-70060bb41ab4",
   "metadata": {},
   "source": [
    "First we obtain the model that will be used to generate the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb8a27cd-2d4e-4ffe-a8c1-ba88e2a42f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multi-qa-distilbert-cos-v1'\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157cd39c-a38a-4a38-9112-a7025ef812f8",
   "metadata": {},
   "source": [
    "Then, a user question is generated and its embedding is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3641d0b-0bde-46c2-bda1-97a61ba9106a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.078222655\n"
     ]
    }
   ],
   "source": [
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "user_question_emb = embedding_model.encode(user_question)\n",
    "print(user_question_emb[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88819039-0bd9-45c7-9146-356a641c1141",
   "metadata": {},
   "source": [
    "**Answer**: 0.07\n",
    "\n",
    "## Q2. Creating the embeddings\n",
    "\n",
    "First, we will prepare the documents list (with ids already included)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13301ab3-9ca9-47ad-b54c-6fef6474f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80d93887-bb5c-4177-b752-57f6b6ef49c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'c02e79ef'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8ccc03-3a28-4089-80c8-7d58ec358e92",
   "metadata": {},
   "source": [
    "We will only need the subset of questions regarding *machine-learning-zoomcamp*. Let's filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6155a3fe-a514-487e-8bc3-6abaefd1cef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n"
     ]
    }
   ],
   "source": [
    "documents_filtered = [doc for doc in documents if doc['course'] == 'machine-learning-zoomcamp']\n",
    "print(len(documents_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a93855e-7e00-4488-8e13-f983962fcbad",
   "metadata": {},
   "source": [
    "Now it is time to generate the embedding for both question and answer fields of all the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4260e843-1525-43c5-9fb3-2e77c3e67ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f092dd20630e42faa018b38a6f951207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = []\n",
    "\n",
    "for doc in tqdm(documents_filtered):\n",
    "    qa_text = f\"{doc['question']} {doc['text']}\"\n",
    "    embeddings.append(embedding_model.encode(qa_text))\n",
    "\n",
    "X = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "973ae4bf-e5f7-4e91-acd4-d09f624626cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 768)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf71053b-8d8d-4b24-b3a0-1d30af0b7f09",
   "metadata": {},
   "source": [
    "**Answer**: (375, 768)\n",
    "\n",
    "## Q3. Search\n",
    "\n",
    "Let's calculate the similarity between the user question from Q1 and the documents from Q2, using the calculated embeddings and the dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3fcf1484-94ea-4445-89b5-94d1bd2b224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = X.dot(user_question_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96d2d033-5d5e-4713-a911-d1df2b6e3046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6506573"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d688a-cdf2-4e68-935b-7939f39c6074",
   "metadata": {},
   "source": [
    "**Answer**: 0.65\n",
    "\n",
    "## Q4. Hit-rate for our search engine\n",
    "\n",
    "First we need to generate the class that performs the vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d3c7f2e-0807-42bd-9c74-6772dc646fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d102ee3a-91a7-43a9-b2ed-f1c9dd3280cd",
   "metadata": {},
   "source": [
    "Use the previous class functions to perform vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc3971b8-1cb9-45e3-ae16-a24ec417b87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'The course has already started. Can I still join it?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': 'ee58a693'},\n",
       " {'text': 'Welcome to the course! Go to the course page (http://mlzoomcamp.com/), scroll down and start going through the course materials. Then read everything in the cohort folder for your cohort’s year.\\nClick on the links and start watching the videos. Also watch office hours from previous cohorts. Go to DTC youtube channel and click on Playlists and search for {course yyyy}. ML Zoomcamp was first launched in 2021.\\nOr you can just use this link: http://mlzoomcamp.com/#syllabus',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'I just joined. What should I do next? How can I access course materials?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '0a278fb2'},\n",
       " {'text': \"The process is automated now, so you should receive the email eventually. If you haven’t, check your promotions tab in Gmail as well as spam.\\nIf you unsubscribed from our newsletter, you won't get course related updates too.\\nBut don't worry, it’s not a problem. To make sure you don’t miss anything, join the #course-ml-zoomcamp channel in Slack and our telegram channel with announcements. This is enough to follow the course.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': \"I filled the form, but haven't received a confirmation email. Is it normal?\",\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '6ba259b1'},\n",
       " {'text': 'Technically, yes. Advisable? Not really. Reasons:\\nSome homework(s) asks for specific python library versions.\\nAnswers may not match in MCQ options if using different languages other than Python 3.10 (the recommended version for 2023 cohort)\\nAnd as for midterms/capstones, your peer-reviewers may not know these other languages. Do you want to be penalized for others not knowing these other languages?\\nYou can create a separate repo using course’s lessons but written in other languages for your own learnings, but not advisable for submissions.\\ntx[source]',\n",
       "  'section': 'Miscellaneous',\n",
       "  'question': 'Can I do the course in other languages, like R or Scala?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '9f261648'},\n",
       " {'text': 'We won’t re-record the course videos. The focus of the course and the skills we want to teach remained the same, and the videos are still up-to-date.\\nIf you haven’t taken part in the previous iteration, you can start watching the videos. It’ll be useful for you and you will learn new things. However, we recommend using Python 3.10 now instead of Python 3.8.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'The course videos are from the previous iteration. Will you release new ones or we’ll use the videos from 2021?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': 'e7ba6b8a'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_engine = VectorSearchEngine(documents=documents_filtered, embeddings=X)\n",
    "search_engine.search(user_question_emb, num_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba61f9c-c9a3-4bd9-a755-40d81d257665",
   "metadata": {},
   "source": [
    "It can be seen that the retrieved documents are related with the user question from Q1. In order to evaluate the performance of the search engine (using hit-rate metric in this case) first we will need to download the ground truth dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16a2da57-2b65-45fd-9b5f-99bff3c2cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17f7aae0-2ccd-4bef-bafd-b8c5c9aae868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Where can I sign up for the course?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'document': '0227b872'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3c3e36-88b1-4500-94f3-d7048bd12d93",
   "metadata": {},
   "source": [
    "Each element on the list corresponds to a question (generated using an LLM) and the id of the main document answering that question. Our search engine, when answering these questions, should include the related documents in the first K retrieved results. This is what we are going to measure with the hit-rate metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e40dace6-48bf-4589-8f12-66ff7c26e821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76dc7f8cf9d4368a1d7bf90a311bb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Num of retrieved documents for each question\n",
    "num_results = 5\n",
    "\n",
    "# Num of total questions to search in the ground truth dataset\n",
    "q_total = len(ground_truth)\n",
    "\n",
    "# Count of total hits over the ground truth dataset\n",
    "hit_count = 0\n",
    "\n",
    "# The search engine has been already initialized with the correct documents and embeddings, so we can directly perform the search\n",
    "for q in tqdm(ground_truth):\n",
    "    # Compute embedding of the ground truth question\n",
    "    q_emb = embedding_model.encode(q['question'])\n",
    "    # Perform search\n",
    "    results = search_engine.search(q_emb, num_results=num_results)\n",
    "    # Check if the results contain the correct document and increase hit count\n",
    "    for r in results:\n",
    "        if r['id']==q['document']:\n",
    "            hit_count = hit_count+1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6ebb45d-ca2f-4859-9a70-ae25edbafc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9398907103825137\n"
     ]
    }
   ],
   "source": [
    "hit_rate = hit_count / q_total\n",
    "print(hit_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db043b19-7ec3-471a-97f8-85e60ba4e677",
   "metadata": {},
   "source": [
    "**Answer**: 0.93\n",
    "\n",
    "## Q5. Indexing with Elasticsearch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
